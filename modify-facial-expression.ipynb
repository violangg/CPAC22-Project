{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_happy_face(img):\n",
    "\n",
    "    # Load the Haar cascade for face detection\n",
    "    face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "    # Detect faces in the image\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "    # Modify the facial expression of each detected face\n",
    "    for (x, y, w, h) in faces:\n",
    "        # Get the coordinates of the mouth\n",
    "        mouth_top = (int(x + w / 4), int(y + 3 * h / 4))\n",
    "        mouth_bottom = (int(x + 3 * w / 4), int(y + 3 * h / 4))\n",
    "\n",
    "        # Modify the facial expression to make the person happy\n",
    "        # Here, we'll move the corners of the mouth upwards and add dimples\n",
    "        new_mouth_top = (mouth_top[0], mouth_top[1] - int(h / 10))\n",
    "        new_mouth_bottom = (mouth_bottom[0], mouth_bottom[1] - int(h / 10))\n",
    "        dimple_left = (int(x + w / 4), int(y + 7 * h / 8))\n",
    "        dimple_right = (int(x + 3 * w / 4), int(y + 7 * h / 8))\n",
    "\n",
    "        # Draw a filled polygon to create the new mouth shape\n",
    "        pts_mouth = [new_mouth_top, mouth_top, mouth_bottom, new_mouth_bottom]\n",
    "        cv2.fillPoly(img, [pts_mouth], (255, 255, 255))\n",
    "\n",
    "        # Draw circles to create dimples\n",
    "        cv2.circle(img, dimple_left, int(h / 20), (0, 0, 0), thickness=-1)\n",
    "        cv2.circle(img, dimple_right, int(h / 20), (0, 0, 0), thickness=-1)\n",
    "\n",
    "    # Display the modified image\n",
    "    cv2.imshow('Modified Image', img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sad_face(img):\n",
    "\n",
    "    # Load the Haar cascade for face detection\n",
    "    face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "    # Detect faces in the image\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "    # Modify the facial expression of each detected face\n",
    "    for (x, y, w, h) in faces:\n",
    "        # Get the coordinates of the mouth\n",
    "        mouth_top = (int(x + w / 4), int(y + 3 * h / 4))\n",
    "        mouth_bottom = (int(x + 3 * w / 4), int(y + 3 * h / 4))\n",
    "\n",
    "        # Modify the facial expression to make the person sad\n",
    "        # Here, we'll move the corners of the mouth downwards\n",
    "        new_mouth_top = (mouth_top[0], mouth_top[1] + int(h / 10))\n",
    "        new_mouth_bottom = (mouth_bottom[0], mouth_bottom[1] + int(h / 10))\n",
    "\n",
    "        # Draw a filled polygon to create the new mouth shape\n",
    "        pts = [new_mouth_top, mouth_top, mouth_bottom, new_mouth_bottom]\n",
    "        cv2.fillPoly(img, [pts], (255, 255, 255))\n",
    "\n",
    "    # Display the modified image\n",
    "    cv2.imshow('Modified Image', img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_relaxed_face(img):\n",
    "\n",
    "    # Load the Haar cascade for face detection\n",
    "    face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "    # Detect faces in the image\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "    # Modify the facial expression of each detected face\n",
    "    for (x, y, w, h) in faces:\n",
    "        # Get the coordinates of the eyes\n",
    "        eye_left = (int(x + w / 4), int(y + h / 3))\n",
    "        eye_right = (int(x + 3 * w / 4), int(y + h / 3))\n",
    "\n",
    "        # Modify the facial expression to make the person look relaxed\n",
    "        # Here, we'll close the eyes and slightly open the mouth\n",
    "        cv2.circle(img, eye_left, int(h / 20), (0, 0, 0), thickness=-1)\n",
    "        cv2.circle(img, eye_right, int(h / 20), (0, 0, 0), thickness=-1)\n",
    "        mouth_top = (int(x + w / 3), int(y + 3 * h / 4))\n",
    "        mouth_bottom = (int(x + 2 * w / 3), int(y + 3 * h / 4))\n",
    "        new_mouth_top = (mouth_top[0], mouth_top[1] + int(h / 20))\n",
    "        new_mouth_bottom = (mouth_bottom[0], mouth_bottom[1] + int(h / 20))\n",
    "        pts_mouth = [new_mouth_top, mouth_top, mouth_bottom, new_mouth_bottom]\n",
    "        cv2.fillPoly(img, [pts_mouth], (255, 255, 255))\n",
    "\n",
    "    # Display the modified image\n",
    "    cv2.imshow('Modified Image', img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_angry_face(img):\n",
    "\n",
    "    # Load the Haar cascade for face detection\n",
    "    face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "    # Detect faces in the image\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "    # Modify the facial expression of each detected face\n",
    "    for (x, y, w, h) in faces:\n",
    "        # Get the coordinates of the mouth\n",
    "        mouth_top = (int(x + w / 4), int(y + 3 * h / 4))\n",
    "        mouth_bottom = (int(x + 3 * w / 4), int(y + 3 * h / 4))\n",
    "\n",
    "        # Modify the facial expression to make the person angry\n",
    "        # Here, we'll move the corners of the mouth downwards and raise the eyebrows\n",
    "        new_mouth_top = (mouth_top[0], mouth_top[1] + int(h / 10))\n",
    "        new_mouth_bottom = (mouth_bottom[0], mouth_bottom[1] + int(h / 10))\n",
    "        new_eyebrow_top = (int(x + w / 4), int(y + h / 4))\n",
    "        new_eyebrow_bottom = (int(x + 3 * w / 4), int(y + h / 4))\n",
    "\n",
    "        # Draw a filled polygon to create the new mouth shape\n",
    "        pts_mouth = [new_mouth_top, mouth_top, mouth_bottom, new_mouth_bottom]\n",
    "        cv2.fillPoly(img, [pts_mouth], (255, 255, 255))\n",
    "\n",
    "        # Draw a line to create the new eyebrow shape\n",
    "        cv2.line(img, new_eyebrow_top, new_eyebrow_bottom, (0, 0, 0), thickness=int(h / 40))\n",
    "\n",
    "    # Display the modified image\n",
    "    cv2.imshow('Modified Image', img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the choose_expression function\n",
    "def choose_expression(coord1, coord2, img):\n",
    "    x1 = coord1\n",
    "    y1 = coord2\n",
    "\n",
    "    # Determine the quadrant in which the coordinates lie\n",
    "    if x1 > 0 and y1 > 0:\n",
    "        # Quadrant 1: happy face\n",
    "        make_happy_face(img)\n",
    "    elif x1 < 0 and y1 > 0:\n",
    "        # Quadrant 2: angry face\n",
    "        make_angry_face(img)\n",
    "    elif x1 < 0 and y1 < 0:\n",
    "        # Quadrant 3: sad face\n",
    "        make_sad_face(img)\n",
    "    elif x1 > 0 and y1 < 0:\n",
    "        # Quadrant 4: relaxed face\n",
    "        make_relaxed_face(img)\n",
    "\n",
    "# Load the input image\n",
    "img = cv2.imread('content.png')\n",
    "\n",
    "# Retrieve the coordinates\n",
    "%store -r coord\n",
    "coord = np.array(coord)\n",
    "coord1 = coord[0]\n",
    "coord2 = coord[1]\n",
    "\n",
    "print(coord1, coord2)\n",
    "\n",
    "# Choose the facial expression based on two input coordinates\n",
    "choose_expression(coord1, coord2, img)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('cpac-proj': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cd425c9899067e04fc55df916c7470f88412bb26de4f5a46a3579bebccfc5675"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
